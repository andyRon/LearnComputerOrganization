深入浅出计算机组成原理
----

https://time.geekbang.org/column/intro/170

发布时间：2019

在计算机专业十余门核心课程中，计算机组成原理是当之无愧的第一课。

无论想要**向上**学习计算机的底层知识，比如编译原理、操作系统、体系结构，还是想要**向下**学习数字电路、数字逻辑等内容，都要先掌握计算机组成原理。

学习计算机组成原理，就是通过指令、计算、CPU、存储系统和 I/O，掌握整个计算机运作过程的核心知识点；通过拆解程序的执行过程，对计算机系统有一个全貌的了解。



# 入门篇

学什么、怎么学、有什么用。

## 0 为什么你需要学习计算机组成原理？

徐文浩，一个正在创业的工程师。目前主要是通过自然语言处理技术，为走向海外的中国企业提供英语的智能客服和社交网络营销服务。

2005 年从上海交通大学计算机系毕业之后，我一直以写代码为生。如果从 7 岁第一次在少年宫写程序开始算起，到今天，我的码龄快有 30 岁了。这些年里，我在 Trilogy Software 写过各种大型企业软件；在 MediaV 这样的广告科技公司，从零开始搭建过支撑每天百亿流量的广告算法系统；2015 年，我又加入了拼多多，参与重写拼多多的交易系统。

这么多年一直在开发软件，我深感软件这个行业变化太快了。语言上，十年前流行 Java，这两年流行 Go；框架上，前两年流行 TensorFlow，最近又流行 PyTorch。我逐渐发现，学习应用层的各种语言、框架，好比在练拳法招式，可以短期给予你回报，而**深入学习“底层知识”，就是在练扎马步、核心肌肉力量，是在提升你自己的“根骨”和“资质”**。

> 如果越早去弄清楚计算机的底层原理，在你的知识体系中“储蓄”起这些知识，也就意味着你有越长的时间来收获学习知识的“利息”。虽然一开始可能不起眼，但是随着时间带来的复利效应，你的长线投资项目，就能让你在成长的过程中越走越快。

### 计算机底层知识的“第一课”

计算机是由 CPU、内存、显示器这些设备组成的硬件，但是，计算机系的学生毕业之后，大部分却都是从事各种软件开发工作。显然，在硬件和软件之间需要一座桥梁，而“计算机组成原理”就扮演了这样一个角色，它既==隔离==了软件和硬件，也提供了让软件无需关心硬件，就能直接操作硬件的==接口==。

![](images/aa5f644331319421eb7549d67d4f8773.jpeg)

### 理论和实践相结合



相关书籍读不下去的原因：

1. **广**。组成原理中的概念非常多，每个概念的信息量也非常大。比如想要理解 CPU 中的算术逻辑单元（也就是 ALU）是怎么实现加法的，需要牵涉到如何把整数表示成二进制，还需要了解这些表示背后的电路、逻辑门、CPU 时钟、触发器等知识。
2. **深**。组成原理中的很多概念，阐述开来就是计算机学科的另外一门核心课程。比如，计算机的指令是怎么从你写的 C、Java 这样的高级语言，变成计算机可以执行的机器码的？如果我们展开并深入讲解这个问题，就会变成《编译原理》这样一门核心课程。
3. **学不能致用**。学东西是要拿来用的，但因为这门课本身的属性，很多人在学习时，常常沉溺于概念和理论中，无法和自己日常的开发工作联系起来，以此来解决工作中遇到的问题，所以，学习往往没有成就感，就很难有动力坚持下去。

## 1  冯·诺依曼体系结构：计算机组成的金字塔

### 计算机的基本硬件组成

三大件：==CPU、内存和主板==

主板是一个有着各种各样，有时候多达数十乃至上百个插槽的配件。

CPU 要插在主板上，内存也要插在主板上。主板的==芯片组（Chipset）==和==总线（Bus）==解决了 CPU 和内存之间如何通信的问题。芯片组控制了数据传输的流转，也就是数据从哪里到哪里的问题。总线则是实际数据传输的高速公路。因此，==总线速度（Bus Speed）==决定了数据能传输得多快。



显卡（Graphics Card） 

GPU（Graphics Processing Unit，图形处理器）

![](images/635b154d3f6c7b5d38c65bc80a808d05.jpeg)

南桥（SouthBridge）芯片组控制鼠标、键盘以及硬盘这些外部设备和 CPU 之间的通信。

“北桥”芯片，以前用来作为“桥”，连接 CPU 和内存、显卡之间的通信。不过，随着时间的变迁，现在的主板上的“北桥”芯片的工作，已经被移到了 CPU 的内部了。

### 冯·诺依曼体系结构

因为手机尺寸的原因，手机制造商们选择把 CPU、内存、网络通信，乃至摄像头芯片，都封装到一个芯片，然后再嵌入到手机主板上。这种方式叫 ==SoC==，也就是 System on a Chip（系统芯片）。

无论是个人电脑、服务器、智能手机，还是 Raspberry Pi 这样的微型卡片机，都遵循着同一个“计算机”的抽象概念，就是==冯·诺依曼体系结构==（Von Neumann architecture），也叫==存储程序计算机==。

存储程序计算机暗含了两个概念：一个是“==可编程==”计算机，一个是“==存储==”计算机。

“不可编程”：计算机是由各种门电路组合而成的，然后通过组装出一个固定的电路板，来完成一个特定的计算程序。一旦需要修改功能，就要重新组装电路。（程序在计算机硬件层面是“写死”的）

最常见的就是老式计算器，电路板设好了加减乘除，做不了任何计算逻辑固定之外的事情。

“存储”表示程序本身是存储在计算机的内存里，可以通过加载不同的程序来解决不同的问题。

> 早年的“Plugboard”这样的插线板式的计算机就是不能存储的。

冯祖师爷，[First Draft of a Report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC)（**First Draft**，《第一份草案》），描述了计算机组成。

> 任何一台计算机的任何一个部件都可以归到运算器、控制器、存储器、输入设备和输出设备中，而所有的现代计算机也都是基于这个基础架构来设计开发的。

而所有的计算机程序，也都可以抽象为从**输入设备**读取输入信息，通过**运算器**和**控制器**来执行存储在**存储器**里的程序，最终把结果输出到**输出设备**中。而我们所有撰写的无论高级还是低级语言的程序，也都是基于这样一个抽象框架来进行运作的。

![img](images/fa8e0e3c96a70cc07b4f0490bfe66f2b.jpeg)

## 2 计算机组成原理知识地图

![](images/12bc980053ea355a201e2b529048e2ff.jpg)



五大基本**组件运算器、控制器、存储器、输入设备和输出设备**。

计算机的两个核心指标，==性能和功耗==。



浮点数（Floating Point）

==CPU时钟==可以用来构造寄存器和内存的锁存器和触发器。

### 入门书籍

《计算机是怎样跑起来的》

《程序是怎样跑起来的》入门微缩版本的“计算机组成原理”。

北京大学免费公开课[《Computer Organization》](https://www.coursera.org/learn/jisuanji-zucheng)：硬件层面的基础实现，比如寄存器、ALU 这些电路是怎么回事

### 深入学习书籍

《计算机组成与设计：硬件 / 软件接口》

《深入理解计算机系统》  https://www.bilibili.com/video/av24540152/

自操作系统大神塔能鲍姆（Andrew S. Tanenbaum）的《计算机组成：结构化方法》，适合作为一个辅助的参考书

《计算机体系结构：量化研究方法》

### 课外阅读

对于资深程序员来说，来自 Redhat 的 What Every Programmer Should Know About Memory 是写出高性能程序不可不读的经典材料

《编码：隐匿在计算机软硬件背后的语言》和《程序员的自我修养：链接、装载和库》是理解计算机硬件和操作系统层面代码执行的优秀阅读材料。

## 3 CPU主频——“性能”究竟是什么？

### 什么是性能？时间的倒数

计算机的性能衡量的两个指标：

- **响应时间**（Response time）或者叫执行时间（Execution time）【“跑得更快”】

![性能监测工具NewRelic中的响应时间，代表了每个外部的Web请求的执行时间](images/4c87a1851aeb6857a323064859da6396.png)

- 吞吐率（Throughput）或者带宽（Bandwidth）【“搬得更多”】

![服务器使用的网络带宽，通常就是一个吞吐率性能指标](images/27cab77c0eec95ec29792e6c3d093d27.png)

==响应时间==指的就是，我们执行一个程序，到底需要花多少时间。花的时间越少，自然性能就越好。

==吞吐率==是指在一定的时间范围内，到底能处理多少事情。这里的“事情”，在计算机里就是处理的数据或者执行的程序指令。

缩短程序的响应时间，一般来说都会提升吞吐率。

除了缩短响应时间，还可以多找几个人一起来搬，这就类似现代的服务器都是 8核、16核的。人多力量大，同时处理数据，在单位时间内就可以处理更多数据，吞吐率自然也就上去了。

响应时间的提升没那么容易，不能像吞吐率那样添加硬件。

一般把性能，定义成响应时间的倒数，也就是：

`性能 = 1/响应时间`

过去几年流行的手机跑分软件，就是把多个预设好的程序在手机上运行，然后根据运行需要的时间，算出一个分数来给出手机的性能评估。而在业界，各大 CPU 和服务器厂商组织了一个叫作 **SPEC**（Standard Performance Evaluation Corporation）的第三方机构，专门用来指定各种“跑分”的规则。

SPEC 提供的 CPU 基准测试程序，就好像 CPU 届的“高考”，通过数十个不同的计算程序，对于 CPU 的性能给出一个最终评分。这些程序丰富多彩，有编译器、解释器、视频压缩、人工智能国际象棋等等，涵盖了方方面面的应用场景。https://www.spec.org/cpu2017/results/cpu2017.html

### 计算机的计时单位：CPU时钟

用时间作为衡量性能的指标，有两个问题。

#### 第一个就是时间不“准”。

统计时间是用类似于“掐秒表”一样，记录程序运行结束的时间减去程序开始运行的时间。这个时间也叫 **==Wall Clock Time==** 或者 **Elapsed Time**，就是在运行程序期间，挂在墙上的钟走掉的时间。

但是，计算机可能同时运行着好多个程序，CPU实际上不停地在各个程序之间进行**切**换。在这些走掉的时间里面，很可能CPU切换去运行别的程序了。而且，有些程序在运行的时候，可能要**从网络、硬盘去读取数据，要等网络和硬盘把数据读出来**，给到内存和CPU。所以说，要想准确统计某个程序运行时间，进而去比较两个程序的实际性能，我们得把这些时间给**刨除**掉。

Linux下的time命令：

```shell
time seq 1000000 | wc -l
1000000

real 0m0.101s
user 0m0.031s
sys  0m0.016s
```

- real time，就是 Wall Clock Time，也就是运行程序整个过程中流逝掉的时间；
- user time，也就是 CPU 在运行你的程序，在用户态运行指令的时间；
- sys time，是 CPU 在运行你的程序，在操作系统内核里运行指令的时间。

而程序实际花费的 **==CPU执行时间（CPU Time）==，就是 user time 加上 sys time**。

上面例子中，实际上程序用了 0.101s，但是 CPU time 只有 0.031+0.016 = 0.047s。运行程序的时间里，只有不到一半是实际花在这个程序上的。

程序实际占用的CPU时间一般比Elapsed Time要少不少：

![程序实际占用的CPU时间一般比Elapsed Time要少不少](images/0b340db019d7e389a2bde4c237ee4700.jpg)

> 备注：最好在云平台上，找一台 1 CPU 的机器来跑这个命令，在多 CPU 的机器上，seq 和 wc 两个命令可能分配到不同的 CPU 上，我们拿到的 user time 和 sys time 是两个 CPU 上花费的时间之和，可能会导致 real time 可能会小于 user time+sys time。



其次，即使我们已经拿到了 CPU 时间，我们也不一定可以直接“比较”出两个程序的性能差异。即使在同一台计算机上，CPU可能满载运行也可能**降频**运行，降频运行的时候自然花的时间会多一些。

除了 CPU 之外，时间这个性能指标还会受到主板、内存这些其他相**关硬件**的影响。所以，我们需要对“时间”这个我们可以感知的指标进行拆解，把程序的 CPU 执行时间变成 ==CPU时钟周期数（CPU Cycles）==和 ==时钟周期时间（Clock Cycle）==的乘积。

```
程序的CPU执行时间 = CPU时钟周期数 x 时钟周期时间
```

> Intel Core-i7-7700HQ 2.8GHz，这里的 2.8GHz 就是电脑CPU的==主频（Frequency/Clock Rate）==，可以先粗浅地认为，CPU 在 1 秒时间内，可以执行的简单指令的数量是 2.8G 条。
>
> 更准确一点描述，这个 2.8GHz 就代表CPU的一个“钟表”能够识别出来的最小的时间间隔。就像我们挂在墙上的挂钟，都是“滴答滴答”一秒一秒地走，所以通过墙上的挂钟能够识别出来的最小时间单位就是秒。
>
> 而在 CPU 内部，和我们平时戴的电子石英表类似，有一个叫==晶体振荡器（Oscillator Crystal）==的东西，简称为==晶振==。我们把晶振当成CPU内部的电子表来使用。晶振带来的每一次“滴答”，就是==时钟周期时间==。
>
> 对应的，2.8GHz的CPU上，时钟周期时间就是1/2.8G。
>
> “==超频==”其实就相当于把买回来的 CPU 内部的钟给调快了，于是 CPU 的计算跟着这个时钟的节奏，也就自然变快了。当然这个快不是没有代价的，CPU 跑得越快，散热的压力也就越大。就和人一样，超过生理极限，CPU 就会崩溃了。

最简单的提升性能方案，自然缩短时钟周期时间，也就是提升主频。但这是软件工程师控制不了的事情。

如果能够减少程序需要的 CPU时钟周期数量，一样能够提升程序性能。



CPU时钟周期数 可以分解 “指令数 × 每条指令的平均时钟周期数（Cycles Per Instruction，简称 ==CPI==）“。上面的公式变为：

```
程序的CPU执行时间 = 指令数 × CPI × Clock Cycle Time
```

想要解决性能问题，其实就是要优化这三者:

1. 时钟周期时间，就是计算机主频。
2. 每条指令的平均时钟周期数 CPI，就是一条指令到底需要多少 CPU Cycle。
3. 指令数，代表执行我们的程序到底需要多少条指令、用哪些指令。这个很多时候就把挑战交给了编译器。同样的代码，编译成计算机指令时候，就有各种不同的表示方式。

> 我们可以把自己想象成一个 CPU，坐在那里写程序。计算机主频就好像是你的打字速度，打字越快，你自然可以多写一点程序。CPI 相当于你在写程序的时候，熟悉各种快捷键，越是打同样的内容，需要敲击键盘的次数就越少。指令数相当于你的程序设计得够合理，同样的程序要写的代码行数就少。如果三者皆能实现，你自然可以很快地写出一个优秀的程序，你的“性能”从外面来看就是好的。



一个程序对应多条语句，一条编程语句可能对应多条指令，一条CPU指令可能需要多个CPU周期才能完成。



### 思考题

> 每次有新手机发布的时候，总会有一些对于手机的跑分结果的议论。乃至于有“作弊”跑分或者“针对跑分优化”的说法。我们能针对“跑分”作弊么？怎么做到呢？“作弊”出来的分数对于手机性能还有参考意义么？





## 4 穿越功耗墙，我们该从哪些方面提升“性能”？

如果要提升计算机的性能，我们可以从指令数、CPI以及CPU主频这三个地方入手。

指令数、CPI不怎么好弄，就针对CPU，在 CPU 上多放一点晶体管，不断提升 CPU的时钟频率，这样就能让CPU变得更快，程序的执行时间就会缩短。

### 功耗：CPU 的“人体极限”



相较于 1978 年到 2000 年，这 20 年里 300 倍的主频提升，从 2000 年到现在的这 19 年，CPU 的主频大概提高了 3 倍。

![CPU的主频变化，在奔腾4时代进入了瓶颈期](images/1826102a89e4cdd31f7573db53dd9280.png)



奔腾 4 的主频为什么没能超过 3.8GHz 的障碍呢？答案就是==功耗==问题。

> 例子：
>
> 一个 3.8GHz 的奔腾 4 处理器，满载功率是 130 瓦。这个 130 瓦是什么概念呢？机场允许带上飞机的充电宝的容量上限是 100 瓦时。如果我们把这个 CPU 安在手机里面，不考虑屏幕内存之类的耗电，这个 CPU 满载运行 45 分钟，充电宝里面就没电了。而 iPhone X 使用 ARM 架构的 CPU，功率则只有 4.5 瓦左右。

CPU一般都被叫作**超大规模集成电路（Very-Large-Scale Integration，VLSI）**。这些电路，实际上都是一个个晶体管组合而成的。CPU 在计算，其实就是让晶体管里面的“开关”不断地去“打开”和“关闭”，来组合完成各种运算和功能。

想要计算得快，一方面，我们要在 CPU 里，同样的面积里面，多放一些晶体管，也就是==增加密度==；另一方面，我们要让晶体管“打开”和“关闭”得更快一点，也就是==提升主频==。而这两者，都会增加功耗，带来耗电和散热的问题。

> 例子：
>
> 可以把一个计算机 CPU 想象成一个巨大的工厂，里面有很多工人，相当于 CPU 上面的晶体管，互相之间协同工作。
>
> 为了工作得快一点，我们要在工厂里多塞一点人。你可能会问，为什么不把工厂造得大一点呢？这是因为，人和人之间如果离得远了，互相之间走过去需要花的时间就会变长，这也会导致性能下降。这就好像如果 CPU 的面积大，晶体管之间的距离变大，电信号传输的时间就会变长，运算速度自然就慢了。
>
> 除了多塞一点人，我们还希望每个人的动作都快一点，这样同样的时间里就可以多干一点活儿了。这就相当于提升 CPU 主频，但是动作快，每个人就要出汗散热。要是太热了，对工厂里面的人来说会中暑生病，对CPU来说就会崩溃出错。

我们会在 CPU 上面抹硅脂、装风扇，乃至用上水冷或者其他更好的散热设备，就好像在工厂里面装风扇、空调，发冷饮一样。但是同样的空间下，装上风扇空调能够带来的散热效果也是有极限的。

因此，在 CPU 里面，能够放下的**晶体管数量和晶体管的“开关”频率也都是有限的**。一个 CPU 的功率可以用一个公式来表示：

```
功耗 ~= 1/2 × 负载电容 × 电压的平方 × 开关频率 × 晶体管数量
```

那么，为了要提升性能，我们需要不断地增加晶体管数量。同样的面积下，我们想要多放一点晶体管，就要把晶体管造得小一点。这个就是平时我们所说的提升“==制程==”。从 28nm 到 7nm，相当于晶体管本身变成了原来的 1/4 大小。这个就相当于我们在工厂里，同样的活儿，我们要找瘦小一点的工人，这样一个工厂里面就可以多一些人。我们还要提升主频，让开关的频率变快，也就是要找手脚更快的工人。

![](images/f59f2f33e308000cb5d2ad017f2ff8ed.jpeg)

但是，**功耗增加太多，就会导致CPU散热跟不上**，这时，我们就需要降低电压。这里有一点非常关键，在整个功耗的公式里面，==功耗和电压的平方是成正比的==。这意味着电压下降到原来的 1/5，整个的功耗会变成原来的 1/25。

事实上，从 5MHz 主频的 8086 到 5GHz 主频的 Intel i9，CPU 的电压已经从 5V 左右下降到了 1V 左右。这也是为什么我们 CPU 的主频提升了 1000 倍，但是功耗只增长了 40 倍。比如说，我写这篇文章用的是 Surface Go，在这样的轻薄笔记本上，微软就是选择了把电压下降到 0.25V 的低电压 CPU，使得笔记本能有更长的续航时间。

### 并行优化，理解阿姆达尔定律

提升响应时间，就好比提升你用的交通工具的速度，比如原本你是开汽车，现在变成了火车乃至飞机。本来开车从上海到北京要 20 个小时，换成飞机就只要 2 个小时了，但是，在此之上，再想要提升速度就不太容易了。我们的 CPU 在奔腾 4 的年代，就好比已经到了飞机这个速度极限。

那你可能要问了，接下来该怎么办呢？相比于给飞机提速，工程师们又想到了新的办法，可以一次同时开 2 架、4 架乃至 8 架飞机，这就好像我们现在用的 2 核、4 核，乃至 8 核的 CPU。

虽然从上海到北京的时间没有变，但是一次飞 8 架飞机能够运的东西自然就变多了，也就是所谓的“吞吐率”变大了。所以，不管你有没有需要，现在 CPU 的性能就是提升了 2 倍乃至 8 倍、16 倍。这也是一个最常见的提升性能的方式，==通过并行提高性能==。

这个思想在很多地方都可以使用。举个例子，我们做机器学习程序的时候，需要计算向量的点积，比如向量 W=[W0,W1,W2,…,W15] 和向量 X=[X0,X1,X2,…,X15]，W⋅X=W0∗X0+W1∗X1+ W2∗X2+…+W15∗X15。这些式子由 16 个乘法和 1 个连加组成。如果你自己一个人用笔来算的话，需要一步一步算 16 次乘法和 15 次加法。如果这个时候我们把这个任务分配给 4 个人，同时去算 W0～W3, W4～W7, W8～W11, W12～W15 这样四个部分的结果，再由一个人进行汇总，需要的时间就会缩短。

![](images/64d6957ecaa696edcf79dc1d5511269d.jpeg)

但是，并不是所有问题，都可以通过并行提高性能来解决。如果想要使用这种思想，需要满足这样几个条件。

- 第一，需要进行的计算，本身可以分解成几个可以并行的任务。好比上面的乘法和加法计算，几个人可以同时进行，不会影响最后的结果。
- 第二，需要能够分解好问题，并确保几个人的结果能够汇总到一起。
- 第三，在“汇总”这个阶段，是没有办法并行进行的，还是得顺序执行，一步一步来。

这就引出了在进行性能优化中，常常用到的一个经验定律，**==阿姆达尔定律（Amdahl’s Law）==**：对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。公式表示：

```
优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间
```

在刚刚的向量点积例子里，4 个人同时计算向量的一小段点积，就是通过并行提高了这部分的计算性能。但是，这 4 个人的计算结果，最终还是要在一个人那里进行汇总相加。这部分汇总相加的时间，是不能通过并行来优化的，也就是上面的公式里面**不受影响的执行时间**这一部分。

比如上面的各个向量的一小段的点积，需要 100ns，加法需要 20ns，总共需要 120ns。这里通过并行 4 个 CPU 有了 4 倍的加速度。那么最终优化后，就有了 100/4+20=45ns。即使我们增加更多的并行度来提供加速倍数，比如有 100 个 CPU，整个时间也需要 100/100+20=21ns。

![](images/f1d05ec439e6377803df741bc07b09e5.jpeg)

### 总结



# 原理篇：指令和运算

## 5 计算机指令：试试用纸带编程

“打孔卡（Punched Card）”

上世纪60年代晚期或70年代初期，Arnold Reinold拍摄的FORTRAN计算程序的穿孔卡照片：

![](images/5d407c051e261902ad9a216c66de3fd7.jpg)

### 在软硬件接口中，CPU做了什么事？

CPU,Central Processing Unit，中央处理器。

从硬件的角度来看，CPU 就是一个超大规模集成电路，通过电路实现了加法、乘法乃至各种各样的处理逻辑。

从软件工程师的角度来讲，CPU 就是一个执行各种**计算机指令**（Instruction Code）的逻辑机器。这里的计算机指令，就好比一门 CPU 能够听得懂的语言，我们也可以把它叫作**机器语言**（Machine Language）。

不同的CPU有各自支持的“语言”，就是不同**==计算机指令集（Instruction Set）==**。

一个计算机程序，不可能只有一条指令，而是由成千上万条指令组成的。但是 CPU 里不能一直放着所有指令，所以计算机程序平时是存储在存储器中的。这种程序指令存储在存储器里面的计算机，就叫作==存储程序型计算机（Stored-program Computer）==。

> 非存储程序型计算机：早就发明了一种叫 Plugboard Computer 的计算设备。我把它直译成“插线板计算机”。在一个布满了各种插口和插座的板子上，工程师们用不同的电线来连接不同的插口和插座，从而来完成各种计算任务。
>
> ![](images/99eb1ab1cdbdfa2d35fce456940ca651.jpg)





### 从编译到汇编，代码怎么变成机器码？



```c
// test.c
int main()
{
  int a = 1; 
  int b = 2;
  a = a + b;
}
```

要让这段程序在一个Linux操作系统上跑起来，需要把整个程序翻译成一个==汇编语言（ASM，Assembly Language）==的程序，这个过程一般叫**编译（Compile）成汇编代码**。

可以再用==汇编器（Assembler）==翻译成==机器码（Machine Code）==。这些机器码由“0”和“1”组成的机器语言表示。这一条条机器码，就是一条条的计算机指令。这样一串串的 16 进制数字，就是CPU能够真正认识的计算机指令。

Linux中可以使用`gcc`和`objdump`把对应的汇编代码和机器码都打印出来：

```shell
$ gcc -g -c test.c
$ objdump -d -M intel -S test.o 

test.o：     文件格式 elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <main>:
// test.c
int main()
{
   0:   objdump: unrecognised disassembler option: intel
d10043ff        sub     sp, sp, #0x10
  int a = 1; 
   4:   52800020        mov     w0, #0x1                        // #1
   8:   b9000fe0        str     w0, [sp, #12]
  int b = 2;
   c:   52800040        mov     w0, #0x2                        // #2
  10:   b9000be0        str     w0, [sp, #8]
  a = a + b;
  14:   b9400fe1        ldr     w1, [sp, #12]
  18:   b9400be0        ldr     w0, [sp, #8]
  1c:   0b000020        add     w0, w1, w0
  20:   b9000fe0        str     w0, [sp, #12]
  24:   52800000        mov     w0, #0x0                        // #0
}
  28:   910043ff        add     sp, sp, #0x10
  2c:   d65f03c0        ret
```

左侧有一堆数字，这些就是一条条机器码；右边有一系列的 push、mov、add、pop 等，这些就是对应的汇编代码。一行 C 语言代码，有时候只对应一条机器码和汇编代码，有时候则是对应两条机器码和汇编代码。汇编代码和机器码之间是一一对应的。

> 可以直接把代码编译成机器码呀，为什么还需要汇编代码呢？
>
> 因为汇编代码其实就是“给程序员看的机器码”，也正因为这样，机器码和汇编代码是一一对应的。

![](images/67cf3c90ac9bde229352e1be0db24b5b.png)





### 解析指令和机器码

日常用的 Intel CPU，有 2000 条左右的 CPU 指令。

常见的指令可以分成五大类：

- 第一类是==算术类指令==。加减乘除，在CPU层面，都会变成一条条算术类指令。
- 第二类是==数据传输类指令==。给变量赋值、在内存里读写数据，用的都是数据传输类指令。
- 第三类是==逻辑类指令==。逻辑上的与或非，都是这一类指令。
- 第四类是==条件分支类指令==。日常写的“if/else”，其实都是条件分支类指令。
- 最后一类是==无条件跳转指令==。写一些大一点的程序，我们常常需要写一些函数或者方法。在调用函数的时候，其实就是发起了一个无条件跳转指令。

![](images/ebfd3bfe5dba764cdcf871e23b29f197.jpeg)

> 汇编器是怎么把对应的汇编代码，翻译成为机器码的？

不同的 CPU 有不同的指令集，也就对应着不同的汇编语言和不同的机器码。以最简单的MIPS指令集为例。

MIPS 是一组由 MIPS 技术公司在 80 年代中期设计出来的 CPU 指令集。就在最近，MIPS 公司把整个指令集和芯片架构都完全开源了。https://www.mips.com/mipsopen/

![](images/b1ade5f8de67b172bf7b4ec9f63589bf.jpeg)

MIPS 的指令是一个32位的整数，高6位叫==操作码（Opcode）==，也就是代表这条指令具体是一条什么样的指令，剩下的 26 位有三种格式，分别是 R、I 和 J。

- ==R指令==是一般用来做算术和逻辑操作，里面有读取和写入数据的寄存器的地址。如果是逻辑位移操作，后面还有位移操作的位移量，而最后的功能码，则是在前面的操作码不够的时候，扩展操作码表示对应的具体指令的。
- ==I指令==，则通常是用在数据传输、条件分支，以及在运算的时候使用的并非变量还是常数的时候。这个时候，没有了位移量和操作码，也没有了第三个寄存器，而是把这三部分直接合并成了一个地址值或者一个常数。
- ==J指令==就是一个跳转指令，高 6 位之外的 26 位都是一个跳转后的地址。



```
add $t0,$s2,$s1
```

以一个简单的加法算术指令为例：【下面都用十进制来表示对应的代码】

对应的 MIPS 指令里 opcode 是 0，rs 代表第一个寄存器 s1 的地址是 17，rt 代表第二个寄存器 s2 的地址是 18，rd 代表目标的临时寄存器 t0 的地址，是 8。因为不是位移操作，所以位移量是 0。把这些数字拼在一起，就变成了一个 MIPS 的加法指令。

![](images/8fced6ff11d3405cdf941f6742b5081d.jpeg)

回到打孔带。如果用打孔代表 1，没有打孔代表 0，用 4 行 8 列代表一条指令来打一个穿孔纸带，那么这条命令大概就长这样：

![](images/1e5ecb8c92b01defee1c2af8c864887c.png)





## 6 指令跳转：原来if...else就是goto

上一节说明了，一个计算机程序是怎么被分解成一条条指令来执行的。

### CPU是如何执行指令的？

一般Intel CPU里面差不多有几百亿个晶体管。实际上，一条条计算机指令执行起来非常复杂。

好在 CPU 在软件层面已经做好了封装。对于做软件的程序员来说，只要知道，写好的代码变成了指令之后，是一条一条**顺序**执行的就可以了。

先不管几百亿的晶体管的背后是怎么通过电路运转起来的，逻辑上，可以认为，CPU 其实就是由一堆**寄存器组**成的。而寄存器就是CPU内部，由多个**触发器（Flip-Flop）或者锁存器（Latches）**组成的简单电路。

触发器和锁存器，其实就是两种不同原理的数字电路组成的**逻辑门**。（数字电路的相关教程🔖）

**N个触发器或者锁存器，就可以组成一个N位（Bit）的寄存器，能够保存N位的数据**。比方说，我们用的64位Intel服务器，寄存器就是64位的。

![](images/cdba5c17a04f0dd5ef05b70368b9a96f.jpg)

一个 CPU 里面会有很多种不同功能的寄存器。三个比较特殊的：

- ==PC寄存器==（Program Counter Register），我们也叫指令地址寄存器（Instruction Address Register）。顾名思义，它就是用来存放下一条需要执行的计算机指令的内存地址。
- ==指令寄存器==（Instruction Register），用来存放当前正在执行的指令。
- ==条件码寄存器==（Status Register），用里面的一个一个标记位（Flag），存放 CPU 进行算术或者逻辑计算的结果。

有些寄存器既可以存放数据，又能存放地址，我们就叫它==通用寄存器==。

实际上，一个程序执行的时候，CPU会根据PC寄存器里的地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。可以看到，一个程序的一条条指令，在内存里面是连续保存的，也会一条条顺序加载。

而有些特殊指令，比如上一节的**J类指令**，也就是**跳转指令**，会修改 PC 寄存器里面的地址值。这样，下一条要执行的指令就不是从内存里面顺序加载的了。事实上，这些跳转指令的存在，也是我们可以在写程序的时候，使用 if…else 条件语句和 while/for 循环语句的原因。

### 从 if…else 来看程序的执行和跳转

```c
// test.c

#include <time.h>
#include <stdlib.h>

int main()
{
  srand(time(NULL));
  int r = rand() % 2;
  int a = 10;
  if (r == 0)
  {
    a = 1;
  } else {
    a = 2;
  }
}
```

对应的汇编代码：

```c
    if (r == 0)
  3b:   83 7d fc 00             cmp    DWORD PTR [rbp-0x4],0x0
  3f:   75 09                   jne    4a <main+0x4a>
    {
        a = 1;
  41:   c7 45 f8 01 00 00 00    mov    DWORD PTR [rbp-0x8],0x1
  48:   eb 07                   jmp    51 <main+0x51>
    }
    else
    {
        a = 2;
  4a:   c7 45 f8 02 00 00 00    mov    DWORD PTR [rbp-0x8],0x2
  51:   b8 00 00 00 00          mov    eax,0x0
    } 
```



🔖

![](images/b439cebb2d85496ad6eef2f61071aefa.jpeg)

### 如何通过 if…else 和 goto 来实现循环？

```c
int main()
{
    int a = 0;
    for (int i = 0; i < 3; i++)
    {
        a += i;
    }
}
```



```c
    for (int i = 0; i <= 2; i++)
   b:   c7 45 f8 00 00 00 00    mov    DWORD PTR [rbp-0x4],0x0
  12:   eb 0a                   jmp    1e 
    {
        a += i;
  14:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x4]
  17:   01 45 fc                add    DWORD PTR [rbp-0x8],eax

  1a:   83 45 f8 01             add    DWORD PTR [rbp-0x4],0x1
  1e:   83 7d f8 02             cmp    DWORD PTR [rbp-0x4],0x2
  22:   7e f0                   jle    14 
  24:   b8 00 00 00 00          mov    eax,0x0
    }
```



![](images/fb50fe39181abb0f70fcfec53cf12317.jpg)





## 7 函数调用：为什么会发生stack overflow？

### 为什么需要程序栈？

```c
// function_example.c
#include <stdio.h>
int static add(int a, int b)
{
    return a+b;
}


int main()
{
    int x = 5;
    int y = 10;
    int u = add(x, y);
}
```



```c
int static add(int a, int b)
{
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
   4:   89 7d fc                mov    DWORD PTR [rbp-0x4],edi
   7:   89 75 f8                mov    DWORD PTR [rbp-0x8],esi
    return a+b;
   a:   8b 55 fc                mov    edx,DWORD PTR [rbp-0x4]
   d:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  10:   01 d0                   add    eax,edx
}
  12:   5d                      pop    rbp
  13:   c3                      ret    
0000000000000014 <main>:
int main()
{
  14:   55                      push   rbp
  15:   48 89 e5                mov    rbp,rsp
  18:   48 83 ec 10             sub    rsp,0x10
    int x = 5;
  1c:   c7 45 fc 05 00 00 00    mov    DWORD PTR [rbp-0x4],0x5
    int y = 10;
  23:   c7 45 f8 0a 00 00 00    mov    DWORD PTR [rbp-0x8],0xa
    int u = add(x, y);
  2a:   8b 55 f8                mov    edx,DWORD PTR [rbp-0x8]
  2d:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  30:   89 d6                   mov    esi,edx
  32:   89 c7                   mov    edi,eax
  34:   e8 c7 ff ff ff          call   0 <add>
  39:   89 45 f4                mov    DWORD PTR [rbp-0xc],eax
  3c:   b8 00 00 00 00          mov    eax,0x0
}
  41:   c9                      leave  
  42:   c3                      ret    
```



![](images/d0c75219d3a528c920c2a593daaf77be.jpeg)



![](images/2361ecf8cf08f07c83377376a31869d1.jpeg)

图中，rbp 是 register base pointer 栈基址寄存器（栈帧指针），指向当前栈帧的栈底地址。rsp 是 register stack pointer 栈顶寄存器（栈指针），指向栈顶元素。



### 如何构造一个 stack overflow？



```c
int a()
{
  return a();
}


int main()
{
  a();
  return 0;
}
```



### 如何利用函数内联进行性能优化？

一个常见的编译器进行自动优化的场景，通常叫**函数内联（Inline）**

```c
#include <stdio.h>
#include <time.h>
#include <stdlib.h>

int static add(int a, int b)
{
    return a+b;
}

int main()
{
    srand(time(NULL));
    int x = rand() % 5
    int y = rand() % 10;
    int u = add(x, y)
    printf("u = %d\n", u)
}
```

```shell
$ gcc -g -c -O function_example_inline.c
$ objdump -d -M intel -S function_example_inline.o
```







![img](images/dca83475560147d4dd492ff283ae0c85.jpeg)

叶子函数（或叶子过程）



## 8 ELF和静态链接：为什么程序无法同时在Linux和Windows下运行？

> 既然我们的程序最终都被变成了一条条机器码去执行，那为什么同一个程序，在同一台计算机上，在 Linux 下可以运行，而在 Windows 下却不行呢？反过来，Windows 上的程序在 Linux 上也是一样不能执行的。可是我们的 CPU 并没有换掉，它应该可以识别同样的指令呀？

### 编译、链接和装载：拆解程序执行



“C 语言代码 - 汇编代码 - 机器码” 这个过程，在计算机上进行的时候是由两部分组成的：

- 第一个部分由编译（Compile）、汇编（Assemble）以及链接（Link）三个阶段组成。在这三个阶段完成之后，我们就生成了一个可执行文件。
- 第二部分，我们通过**装载器（Loader）**把可执行文件装载（Load）到内存中。CPU 从内存中读取指令和数据，来开始真正执行程序。

![](images/997341ed0fa9018561c7120c19cfa2a7.jpg)

### ELF格式和链接：理解链接过程

程序最终是通过装载器变成指令和数据的

![](images/276a740d0eabf5f4be905fe7326d9fb3.jpg)

ELF 文件格式把各种信息，分成一个一个的 Section 保存起来。ELF 有一个基本的文件头（File Header），用来表示这个文件的基本属性，比如是否是可执行文件，对应的 CPU、操作系统等等。除了这些基本属性之外，大部分程序还有这么一些 Section：

1. 首先是.text Section，也叫作**代码段**或者指令段（Code Section），用来保存程序的代码和指令；
2. 接着是.data Section，也叫作**数据段**（Data Section），用来保存程序里面设置好的初始化数据信息；
3. 然后就是.rel.text Secion，叫作**重定位表**（Relocation Table）。重定位表里，保留的是当前的文件里面，哪些跳转地址其实是我们不知道的。比如上面的 link_example.o 里面，我们在 main 函数里面调用了 add 和 printf 这两个函数，但是在链接发生之前，我们并不知道该跳转到哪里，这些信息就会存储在重定位表里；
4. 最后是.symtab Section，叫作**符号表**（Symbol Table）。符号表保留了我们所说的当前文件里面定义的函数名称和对应地址的地址簿。



![](images/f62da9b29aa53218f8907851df27f912.jpeg)

## 9 程序装载：“640K内存”真的不够用么？

### 程序装载面临的挑战

通过链接器，把多个文件合并成一个最终可执行文件。在运行这些可执行文件的时候，我们其实是通过一个装载器，解析 ELF 或者 PE 格式的可执行文件。装载器会把对应的指令和数据加载到内存里面来，让CPU去执行。

装载到内存里面，实际上装载器需要满足两个要求：

- 第一，可执行程序加载后占用的内存空间应该是连续的。

- 第二，我们需要同时加载很多个程序，并且不能让程序自己规定在内存中加载的位置。



虚拟内存地址（Virtual Memory Address）

物理内存地址（Physical Memory Address）



### 内存分段

这种找出一段连续的物理内存和虚拟内存地址进行映射的方法，叫==分段（Segmentation）==。这里的段，就是指系统分配出来的那个连续的内存空间。

![](images/24596e1e66d88c5d077b4c957d0d7f18.png)

分段解决了程序本身不需要关心具体的物理内存地址的问题，缺点是**内存碎片**（Memory Fragmentation）的问题。

![img](images/57211af3053ed621aeb903433c6c10d1.png)

解决的办法叫==内存交换==（Memory Swapping）。



### 内存分页



和分段这样分配一整段连续的空间给到程序相比，分页是把整个物理内存空间切成一段段固定尺寸的大小。

```shell
$ getconf PAGE_SIZE
```

由于内存空间都是预先划分好的，也就没有了不能使用的碎片，而只有被释放出来的很多 4KB 的页。即使内存空间不够，需要让现有的、正在运行的其他程序，通过内存交换释放出一些内存的页出来，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，让整个机器被内存交换的过程给卡住。

![](images/0cf2f08e1ceda473df71189334857cf0.png)



缺页错误（Page Fault）





## 10 动态链接：程序内部的“共享单车”

“链接”其实有点儿像我们日常生活中的**标准化**、**模块化**生产。我们有一个可以生产标准螺帽的生产线，就可以生产很多个不同的螺帽。只要需要螺帽，我们都可以通过**链接**的方式，去**复制**一个出来，放到需要的地方去，大到汽车，小到信箱。

![](images/092dfd81e3cc45ea237bb85557bbfa51.jpg)

### 链接可以分动、静，共享运行省内存

内存空间不够用

==动态链接（Dynamic Link）==，想要“链接”的，不是存储在硬盘上的目标文件代码，而是加载到内存中的**==共享==库（Shared Libraries）**。

这个加载到内存中的共享库会被很多个程序的指令调用到。在 Windows 下，这些共享库文件就是`.dll` 文件，也就是 **Dynamic-Link Libary（DLL，动态链接库）**。在 Linux 下，这些共享库文件就是`.so` 文件，也就是 **Shared Object**（一般我们也称之为动态链接库）。这两大操作系统下的文件名后缀，一个用了“动态链接”的意思，另一个用了“共享”的意思，正好覆盖了两方面的含义。

![](images/2980d241d3c7cbfa3724cb79b801d160.jpg)



==静态链接（Static Link）==



### 地址无关很重要，相对地址解烦恼

要想要在程序运行的时候共享代码，这些机器码必须是“地址无关”的。



![img](images/8cab516a92fd3d7e951887808597094a.jpg)

对于所有动态链接共享库的程序来讲，**虽然我们的共享库用的都是同一段物理内存地址，但是在不同的应用程序里，它所在的虚拟内存地址是不同的**。



### PLT 和 GOT，动态链接的解决方案



程序链接表（Procedure Link Table）



全局偏移表（GOT，Global Offset Table）



![](images/1144d3a2d4f3f4f87c349a93429805c8.jpg)





## 11 二进制编码：“手持两把锟斤拷，口中疾呼烫烫烫”？

### 理解二进制的“逢二进一”



### 字符串的表示，从编码到数字

字符串（Character String）

ASCII 码（American Standard Code for Information Interchange，美国信息交换标准代码）



字符集（Charset）和字符编码（Character Encoding）

![](images/9911c58d79e8a1f106d48a83457d193e.jpg)



## 12 理解电路：从电报机到门电路，我们如何做到“千里传信”？

### 从信使到电报，我们怎么做到“千里传书”？

从信息编码的角度来说，金、鼓、灯塔、烽火台类似电报的二进制编码。电报传输的信号有两种，一种是短促的**点信号**（dot 信号），一种是长一点的**划信号**（dash 信号）。我们把“点”当成“1”，把“划”当成“0”。这样一来，我们的电报信号就是另一种特殊的二进制编码了。电影里最常见的电报信号是“SOS”，这个信号表示出来就是 “点点点划划划点点点”。

比起灯塔和烽火台这样的设备，电报信号有两个明显的优势。

- 第一，信号的传输距离迅速增加。因为电报本质上是通过电信号来进行传播的，所以从输入信号到输出信号基本上没有延时。
- 第二，输入信号的速度加快了很多。

而且，制造一台电报机也非常容易。电报机本质上就是一个“蜂鸣器 + 长长的电线 + 按钮开关”。蜂鸣器装在接收方手里，开关留在发送方手里。双方用长长的电线连在一起。当按钮开关按下的时候，电线的电路接通了，蜂鸣器就会响。短促地按下，就是一个短促的点信号；按的时间稍微长一些，就是一个稍长的划信号。

![有了电池开关和铃铛，你就有了最简单的摩尔斯电码发报机](images/283742f3a72eba22f6b4ae97e21c4112.jpg)





### 理解继电器，给跑不动的信号续一秒



![](images/1186a10341202ea36df27cba95f1cbea.jpg)





## 13 加法器：如何像搭乐高一样搭电路（上）？

![](images/94194480bcfd3b5366e4649ee80de4f6.jpg)

### 异或门和半加器



![其实加法器就是想一个办法把这三排开关电路连起来](images/281879883d285478b7771f576f4b3066.jpg)



![半加器的电路演示](images/5860fd8c4ace079b40e66b9568d2b81e.jpg)

### 全加器



![全加器就是两个半加器加上一个或门](images/3f11f278ba8f24209a56fb3ee1ca9e2a.jpg)



![8 位加法器可以由 8 个全加器串联而成](images/68cd38910f526c149d232720b82b6ca1.jpeg)





![](images/8a7740f698236fda4e5f900d88fdf194.jpg)





## 14 乘法器：如何像搭乐高一样搭电路（下）？

十进制中的 13 乘以 9，转换成二进制：

![](images/498fdfa2dc95631068d65e0ff5769c4b.jpg)

### 顺序乘法的实现过程





![乘法器硬件结构示意图](images/cb809de19088d08767279715f07482e9.jpg)



![](images/0615e5e4406617ee6584adbb929f9571.jpeg)

### 并行加速方法



![目前的乘法实现就像是单败淘汰赛](images/07f7b0eedbf1a00fc72be7e2bd0d96ef.jpg)



![通过并联更多的 ALU，加上更多的寄存器，我们也能加速乘法](images/6646b90ea563c6b87dc20bbd81c54b98.jpeg)

### 电路并行

门延迟（Gate Delay）



![C4 是前 4 位的计算结果是否进位的门电路表示](images/0c2c69f9bbd1d8eca36f560cbe092169.jpg)



## 15 浮点数和定点数（上）：怎么用有限的Bit表示尽可能多的信息？

### 浮点数的不精确性





### 定点数的表示



BCD 编码（Binary-Coded Decimal）



### 浮点数的表示

浮点数（Floating Point），也就是 float 类型



![img](images/914b71bf1d85fb6ed76e1135f39b6941.jpg)

单精度的 32 个比特可以分成三部分：

- 符号位
- 指数位
- 有效数位

$$(-1)^s * 1.f * 2^e$$



## 16 浮点数和定点数（下）：深入理解浮点数到底有什么用？

### 浮点数的二进制转化





### 浮点数的加法和精度损失





### Kahan Summation 算法











# 原理篇：处理器



## 17 建立数据通路（上）：指令+运算=CPU

### 指令周期（Instruction Cycle）



1. Fetch（取得指令），也就是从 PC 寄存器里找到对应的指令地址，根据指令地址从内存里把具体的指令，加载到指令寄存器中，然后把 PC 寄存器自增，好在未来执行下一条指令。
2. Decode（指令译码），也就是根据指令寄存器里面的指令，解析成要进行什么样的操作，是 R、I、J 中的哪一种指令，具体要操作哪些寄存器、数据或者内存地址。
3. Execute（执行指令），也就是实际运行对应的 R、I、J 这些特定的指令，进行算术逻辑操作、数据传输或者直接的地址跳转。
4. 重复进行 1～3 的步骤。

![img](images/1840bead02cfbe5d8f70e2f0a7b962a7.jpg)



![](images/bde3548a4789ba49cab74c8c1ab02a67.jpeg)



![](images/1a7d2d6cf7cb78a8f48775268f452e48.jpeg)



### 建立数据通路



指令译码器将输入的机器码，解析成不同的操作码和操作数，然后传输给 ALU 进行计算

![](images/46087a894b4ac182fab83ac3786cad6f.jpeg)



### CPU 所需要的硬件电路







## 18 建立数据通路（中）：指令+运算=CPU

组合逻辑电路（Combinational Logic Circuit）

时序逻辑电路（Sequential Logic Circuit）



### 时钟信号的硬件实现



![](images/57684c12e7bf8ef429220405b0e3bdc0.jpeg)





### 通过 D 触发器实现存储功能

![](images/dc6dcce612b2fd51939d7ec44b3fe1de.jpeg)



![](images/9e9bc411aa8c7bf2f080f306a0fb8bd8.jpeg)

![](images/d749acce21756d89c35ee19545cfebbb.jpeg)



## 19 建立数据通路（下）：指令+运算=CPU



### PC 寄存器所需要的计数器

![](images/1ed21092022057ed192a7d9aff76144c.jpg)



单指令周期处理器（Single Cycle Processor）





### 读写数据所需要的译码器









### 建立数据通路，构造一个最简单的 CPU



![CPU 实现的抽象逻辑图](images/6863e10fc635791878d1ecd57618b871.jpeg)







## 20 面向流水线的指令设计（上）：一心多用的现代CPU



### 单指令周期处理器



![img](images/6c85e2dd9b9988d8a458fb1200d96eee.jpeg)

快速执行完成的指令，需要等待满一个时钟周期，才能执行下一条指令



![前一条指令的写入，在后一条指令的读取之前](images/3097988ae8dfc82e33ab80234bd5a29b.jpeg)





### 现代处理器的流水线设计



![流水线执行示意图](images/1e880fa8b1eab511583267e68f0541ad.jpeg)

### 超长流水线的性能瓶颈



![](images/d9e141af3f2c5eedd5aed438388cfe26.jpeg)



## 21 面向流水线的指令设计（下）：奔腾4是怎么失败的？



### “主频战争”带来的超长流水线



![](images/b055676975e68a7d4014e46969058f6a.jpeg)

### 新的挑战：冒险和分支预测





## 22 冒险和预测（一）：hazard是“危”也是“机”

CPU的流水线需要解决的三大冒险：结构冒险（Structural Hazard）、数据冒险（Data Hazard）以及控制冒险（Control Hazard）。

### 结构冒险：为什么工程师都喜欢用机械键盘？



![同一个时钟周期，两个不同指令访问同一个资源](images/fff791c9c4066ba86dcce350e9710822.png)





现代 CPU 架构，借鉴了哈佛架构，在高速缓存层面拆分成指令缓存和数据缓存

![img](images/e7508cb409d398380753b292b6df8391.jpeg)



### 数据冒险：三种不同的依赖关系



#### 先写后读（Read After Write，RAW）



#### 先读后写（Write After Read，WAR）



#### 写后再写（Write After Write，WAW）





### 再等等：通过流水线停顿解决数据冒险

流水线停顿（Pipeline Stall），或者叫流水线冒泡（Pipeline Bubbling）



## 23 冒险和预测（二）：流水线里的接力赛

### NOP 操作和指令对齐

![](images/1e880fa8b1eab511583267e68f0541ad-20240313164027984.jpeg)



### 流水线里的接力赛：操作数前推



![](images/94dda2330b07c08530540ae11838c569.jpeg)





## 24 冒险和预测（三）：CPU里的“线程池”

### 填上空闲的 NOP：上菜的顺序不必是点菜的顺序





### CPU 里的“线程池”：理解乱序执行



## 25 冒险和预测（四）：今天下雨了，明天还会下雨么？

### 分支预测：今天下雨了，明天还会继续下雨么？





### 为什么循环嵌套的改变会影响性能？



## 26 Superscalar和VLIW：如何让CPU的吞吐率超过1？

### 多发射与超标量：同一时间执行的两条指令



### Intel 的失败之作：安腾的超长指令字设计





## 27 SIMD：如何加速矩阵乘法？

单指令多数据流（SIMD）技术

### 超线程：Intel 多卖给你的那一倍 CPU



### SIMD：如何加速矩阵乘法？



## 28 异常和中断：程序出错了怎么办？

### 异常：硬件、系统和应用的组合拳



### 异常的分类：中断、陷阱、故障和中止



### 异常的处理：上下文切换



## 29 CISC和RISC：为什么手机芯片都是ARM？

复杂指令集（Complex Instruction Set Computing，简称 CISC）

精简指令集（Reduced Instruction Set Computing，简称 RISC）



### Intel 的进化：微指令架构的出现



### ARM 和 RISC-V：CPU 的现在与未来



## 30 GPU（上）：为什么玩游戏需要使用GPU？

### GPU 的历史进程



### 图形渲染的流程



对于图像进行实时渲染的过程，可以被分解成下面这样 5 个步骤：

#### 1 顶点处理（Vertex Processing）



#### 2 图元处理（Primitive Processing）



#### 3 栅格化（Rasterization）



#### 4 片段处理（Fragment Processing）



#### 5 像素操作（Pixel Operations）



### 解放图形渲染的 GPU



## 31 GPU（下）：为什么深度学习需要使用GPU？



### Shader 的诞生和可编程图形处理器



### 现代 GPU 的三个核心创意



#### 芯片瘦身



#### 多核并行和 SIMT



#### GPU 里的“超线程”





### GPU 在深度学习上的性能差异



## 32 FPGA和ASIC：计算机体系结构的黄金时代

### FPGA

FPGA，也就是现场可编程门阵列（Field-Programmable Gate Array）



### ASIC

ASIC（Application-Specific Integrated Circuit），也就是专用集成电路



## 33 解读TPU：设计和拆解一块ASIC芯片

### TPU V1 想要解决什么问题？



### 深入理解 TPU V1

#### 快速上线和向前兼容，一个 FPU 的设计



#### 专用电路和大量缓存，适应推断的工作流程

![](images/6a14254b2bda4dd42adac6a2129e8bae.jpeg)

#### 细节优化，使用 8 Bits 数据







### 用数字说话，TPU 的应用效果





## 34 理解虚拟机：你在云上拿到的计算机是什么样的？

### 缘起分时系统



### 从“黑色星期五”到公有云



### 虚拟机的技术变迁















# 原理篇：存储和I/O系统

## 35 存储器层次结构全景：数据存储的大金字塔长什么样？

### 理解存储器的层次结构



SRAM

DRAM

存储器的层级结构

使用存储器的时候，该如何权衡价格和性能？



## 36 局部性原理：数据库性能跟不上，加个缓存就好了？

### 理解局部性原理



### 如何花最少的钱，装下亚马逊的所有商品？



## 37 高速缓存（上）：“4毫秒”究竟值多少钱？



## 38 高速缓存（下）：你确定你的数据更新了么？

### “隐身”的变量



### CPU 高速缓存的写入

写直达（Write-Through）



写回（Write-Back）



## 39 MESI协议：如何让多核CPU的高速缓存保持一致？

### 缓存一致性问题



### 总线嗅探机制和 MESI 协议



## 40 理解内存（上）：虚拟内存和内存保护是什么？

### 简单页表



### 多级页表



## 41 理解内存（下）：解析TLB和内存保护

### 加速地址转换：TLB



### 安全性与内存保护

#### 可执行空间保护



#### 地址空间布局随机化



## 42 总线：计算机内部的高速公路

### 降低复杂性：总线的设计思路来源



### 理解总线：三种线路和多总线架构



## 43 输入输出设备：我们并不是只能用灯泡显示“0”和“1”

### 接口和设备：经典的适配器模式



### CPU 是如何控制 I/O 设备的？



### 信号和地址：发挥总线的价值



## 44 理解IO_WAIT：I/O性能到底是怎么回事儿？

### IO 性能、顺序访问和随机访问



如何定位 IO_WAIT？



## 45 机械硬盘：Google早期用过的“黑科技”

### 拆解机械硬盘



### Partial Stroking：根据场景提升性能



## 46 SSD硬盘（上）：如何完成性能优化的KPI？

### SSD 的读写原理



### SLC、MLC、TLC 和 QLC



### P/E 擦写问题



### SSD 读写的生命周期



## 47 SSD硬盘（下）：如何完成性能优化的KPI？

磨损均衡、TRIM 和写入放大效应



FTL 和磨损均衡



TRIM 指令的支持



写入放大



AeroSpike：如何最大化 SSD 的使用效率？



## 48 DMA：为什么Kafka这么快？

直接内存访问（Direct Memory Access）技术



### Kafka 的实现原理





## 49 数据完整性（上）：硬件坏了怎么办？



### 单比特翻转：软件解决不了的硬件错误



### 奇偶校验和校验位：捕捉错误的好办法





## 50 数据完整性（下）：如何还原犯罪现场？

### 海明码：我们需要多少信息冗余？



### 海明码的纠错原理



### 海明距离：形象理解海明码的作用



## 51 分布式计算：如果所有人的大脑都联网会怎样？

### 从硬件升级到水平扩展



### 理解高可用性和单点故障













# 应用篇

理解了计算机各个组件的运作之后，最后一个模块将手把手带你实操。利用存储器层次结构设计大型 DMP 系统，并通过 Disruptor，跟你一起感受 CPU 的风驰电掣，让你真正学有所用。

## 52 设计大型DMP系统（上）：MongoDB并不是什么灵丹妙药



DMP：数据管理平台



## 53 设计大型DMP系统（下）：SSD拯救了所有的DBA

### 关系型数据库：不得不做的随机读写



### Cassandra：顺序写和随机读

Cassandra 的数据模型



Cassandra 的读操作



### SSD：DBA 们的大救星



## 54 理解Disruptor（上）：带你体会CPU高速缓存的风驰电掣

### Padding Cache Line，体验高速缓存的威力



### 使用 RingBuffer，利用缓存和分支预测





## 55 理解Disruptor（下）：不需要换挡和踩刹车的CPU，有多快？

### 缓慢的锁



### 无锁的 RingBuffer





