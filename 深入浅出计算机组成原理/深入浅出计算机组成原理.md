深入浅出计算机组成原理
----

https://time.geekbang.org/column/intro/170

发布时间：2019

在计算机专业十余门核心课程中，计算机组成原理是当之无愧的第一课。

无论想要**向上**学习计算机的底层知识，比如编译原理、操作系统、体系结构，还是想要**向下**学习数字电路、数字逻辑等内容，都要先掌握计算机组成原理。

学习计算机组成原理，就是通过指令、计算、CPU、存储系统和 I/O，掌握整个计算机运作过程的核心知识点；通过拆解程序的执行过程，对计算机系统有一个全貌的了解。



# 入门篇

学什么、怎么学、有什么用。

## 0 为什么你需要学习计算机组成原理？

徐文浩，一个正在创业的工程师。目前主要是通过自然语言处理技术，为走向海外的中国企业提供英语的智能客服和社交网络营销服务。

2005 年从上海交通大学计算机系毕业之后，我一直以写代码为生。如果从 7 岁第一次在少年宫写程序开始算起，到今天，我的码龄快有 30 岁了。这些年里，我在 Trilogy Software 写过各种大型企业软件；在 MediaV 这样的广告科技公司，从零开始搭建过支撑每天百亿流量的广告算法系统；2015 年，我又加入了拼多多，参与重写拼多多的交易系统。

这么多年一直在开发软件，我深感软件这个行业变化太快了。语言上，十年前流行 Java，这两年流行 Go；框架上，前两年流行 TensorFlow，最近又流行 PyTorch。我逐渐发现，学习应用层的各种语言、框架，好比在练拳法招式，可以短期给予你回报，而**深入学习“底层知识”，就是在练扎马步、核心肌肉力量，是在提升你自己的“根骨”和“资质”**。

> 如果越早去弄清楚计算机的底层原理，在你的知识体系中“储蓄”起这些知识，也就意味着你有越长的时间来收获学习知识的“利息”。虽然一开始可能不起眼，但是随着时间带来的复利效应，你的长线投资项目，就能让你在成长的过程中越走越快。

### 计算机底层知识的“第一课”

计算机是由 CPU、内存、显示器这些设备组成的硬件，但是，计算机系的学生毕业之后，大部分却都是从事各种软件开发工作。显然，在硬件和软件之间需要一座桥梁，而“计算机组成原理”就扮演了这样一个角色，它既==隔离==了软件和硬件，也提供了让软件无需关心硬件，就能直接操作硬件的==接口==。

![](images/aa5f644331319421eb7549d67d4f8773.jpeg)

### 理论和实践相结合



相关书籍读不下去的原因：

1. **广**。组成原理中的概念非常多，每个概念的信息量也非常大。比如想要理解 CPU 中的算术逻辑单元（也就是 ALU）是怎么实现加法的，需要牵涉到如何把整数表示成二进制，还需要了解这些表示背后的电路、逻辑门、CPU 时钟、触发器等知识。
2. **深**。组成原理中的很多概念，阐述开来就是计算机学科的另外一门核心课程。比如，计算机的指令是怎么从你写的 C、Java 这样的高级语言，变成计算机可以执行的机器码的？如果我们展开并深入讲解这个问题，就会变成《编译原理》这样一门核心课程。
3. **学不能致用**。学东西是要拿来用的，但因为这门课本身的属性，很多人在学习时，常常沉溺于概念和理论中，无法和自己日常的开发工作联系起来，以此来解决工作中遇到的问题，所以，学习往往没有成就感，就很难有动力坚持下去。

## 1  冯·诺依曼体系结构：计算机组成的金字塔

### 计算机的基本硬件组成

三大件：==CPU、内存和主板==

主板是一个有着各种各样，有时候多达数十乃至上百个插槽的配件。

CPU 要插在主板上，内存也要插在主板上。主板的==芯片组（Chipset）==和==总线（Bus）==解决了 CPU 和内存之间如何通信的问题。芯片组控制了数据传输的流转，也就是数据从哪里到哪里的问题。总线则是实际数据传输的高速公路。因此，==总线速度（Bus Speed）==决定了数据能传输得多快。



显卡（Graphics Card） 

GPU（Graphics Processing Unit，图形处理器）

![](images/635b154d3f6c7b5d38c65bc80a808d05.jpeg)

南桥（SouthBridge）芯片组控制鼠标、键盘以及硬盘这些外部设备和 CPU 之间的通信。

“北桥”芯片，以前用来作为“桥”，连接 CPU 和内存、显卡之间的通信。不过，随着时间的变迁，现在的主板上的“北桥”芯片的工作，已经被移到了 CPU 的内部了。

### 冯·诺依曼体系结构

因为手机尺寸的原因，手机制造商们选择把 CPU、内存、网络通信，乃至摄像头芯片，都封装到一个芯片，然后再嵌入到手机主板上。这种方式叫 ==SoC==，也就是 System on a Chip（系统芯片）。

无论是个人电脑、服务器、智能手机，还是 Raspberry Pi 这样的微型卡片机，都遵循着同一个“计算机”的抽象概念，就是==冯·诺依曼体系结构==（Von Neumann architecture），也叫==存储程序计算机==。

存储程序计算机暗含了两个概念：一个是“==可编程==”计算机，一个是“==存储==”计算机。

“不可编程”：计算机是由各种门电路组合而成的，然后通过组装出一个固定的电路板，来完成一个特定的计算程序。一旦需要修改功能，就要重新组装电路。（程序在计算机硬件层面是“写死”的）

最常见的就是老式计算器，电路板设好了加减乘除，做不了任何计算逻辑固定之外的事情。

“存储”表示程序本身是存储在计算机的内存里，可以通过加载不同的程序来解决不同的问题。

> 早年的“Plugboard”这样的插线板式的计算机就是不能存储的。

冯祖师爷，[First Draft of a Report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC)（**First Draft**，《第一份草案》），描述了计算机组成。

> 任何一台计算机的任何一个部件都可以归到运算器、控制器、存储器、输入设备和输出设备中，而所有的现代计算机也都是基于这个基础架构来设计开发的。

而所有的计算机程序，也都可以抽象为从**输入设备**读取输入信息，通过**运算器**和**控制器**来执行存储在**存储器**里的程序，最终把结果输出到**输出设备**中。而我们所有撰写的无论高级还是低级语言的程序，也都是基于这样一个抽象框架来进行运作的。

![img](images/fa8e0e3c96a70cc07b4f0490bfe66f2b.jpeg)

## 2 计算机组成原理知识地图

![](images/12bc980053ea355a201e2b529048e2ff.jpg)



五大基本**组件运算器、控制器、存储器、输入设备和输出设备**。

计算机的两个核心指标，==性能和功耗==。



浮点数（Floating Point）

==CPU时钟==可以用来构造寄存器和内存的锁存器和触发器。

### 入门书籍

《计算机是怎样跑起来的》

《程序是怎样跑起来的》入门微缩版本的“计算机组成原理”。

北京大学免费公开课[《Computer Organization》](https://www.coursera.org/learn/jisuanji-zucheng)：硬件层面的基础实现，比如寄存器、ALU 这些电路是怎么回事

### 深入学习书籍

《计算机组成与设计：硬件 / 软件接口》

《深入理解计算机系统》  https://www.bilibili.com/video/av24540152/

自操作系统大神塔能鲍姆（Andrew S. Tanenbaum）的《计算机组成：结构化方法》，适合作为一个辅助的参考书

《计算机体系结构：量化研究方法》

### 课外阅读

对于资深程序员来说，来自 Redhat 的 What Every Programmer Should Know About Memory 是写出高性能程序不可不读的经典材料

《编码：隐匿在计算机软硬件背后的语言》和《程序员的自我修养：链接、装载和库》是理解计算机硬件和操作系统层面代码执行的优秀阅读材料。

## 3 CPU主频——“性能”究竟是什么？

### 什么是性能？时间的倒数

计算机的性能衡量的两个指标：

- **响应时间**（Response time）或者叫执行时间（Execution time）【“跑得更快”】

![性能监测工具NewRelic中的响应时间，代表了每个外部的Web请求的执行时间](images/4c87a1851aeb6857a323064859da6396.png)

- 吞吐率（Throughput）或者带宽（Bandwidth）【“搬得更多”】

![服务器使用的网络带宽，通常就是一个吞吐率性能指标](images/27cab77c0eec95ec29792e6c3d093d27.png)

响应时间指的就是，我们执行一个程序，到底需要花多少时间。花的时间越少，自然性能就越好。

吞吐率是指在一定的时间范围内，到底能处理多少事情。这里的“事情”，在计算机里就是处理的数据或者执行的程序指令。

缩短程序的响应时间，一般来说都会提升吞吐率。

除了缩短响应时间，还可以多找几个人一起来搬，这就类似现代的服务器都是 8 核、16 核的。人多力量大，同时处理数据，在单位时间内就可以处理更多数据，吞吐率自然也就上去了。

响应时间的提升没那么容易，不能像吞吐率那样添加硬件。

一般把性能，定义成响应时间的倒数，也就是：

`性能 = 1/响应时间`

过去几年流行的手机跑分软件，就是把多个预设好的程序在手机上运行，然后根据运行需要的时间，算出一个分数来给出手机的性能评估。而在业界，各大 CPU 和服务器厂商组织了一个叫作 **SPEC**（Standard Performance Evaluation Corporation）的第三方机构，专门用来指定各种“跑分”的规则。

SPEC 提供的 CPU 基准测试程序，就好像 CPU 届的“高考”，通过数十个不同的计算程序，对于 CPU 的性能给出一个最终评分。这些程序丰富多彩，有编译器、解释器、视频压缩、人工智能国际象棋等等，涵盖了方方面面的应用场景。https://www.spec.org/cpu2017/results/cpu2017.html

### 计算机的计时单位：CPU 时钟

用时间作为衡量性能的指标，有两个问题。

#### 第一个就是时间不“准”。

统计时间是用类似于“掐秒表”一样，记录程序运行结束的时间减去程序开始运行的时间。这个时间也叫 **Wall Clock Time** 或者 **Elapsed Time**，就是在运行程序期间，挂在墙上的钟走掉的时间。

但是，计算机可能同时运行着好多个程序，CPU实际上不停地在各个程序之间进行**切**换。在这些走掉的时间里面，很可能CPU切换去运行别的程序了。而且，有些程序在运行的时候，可能要**从网络、硬盘去读取数据，要等网络和硬盘把数据读出来**，给到内存和CPU。所以说，要想准确统计某个程序运行时间，进而去比较两个程序的实际性能，我们得把这些时间给**刨除**掉。

Linux下的time命令：

```shell
time seq 1000000 | wc -l
1000000

real 0m0.101s
user 0m0.031s
sys  0m0.016s
```

- real time，就是 Wall Clock Time，也就是运行程序整个过程中流逝掉的时间；
- user time，也就是 CPU 在运行你的程序，在用户态运行指令的时间；
- sys time，是 CPU 在运行你的程序，在操作系统内核里运行指令的时间。

而程序实际花费的 **CPU执行时间（CPU Time），就是 user time 加上 sys time**。

上面例子中，实际上程序用了 0.101s，但是 CPU time 只有 0.031+0.016 = 0.047s。运行程序的时间里，只有不到一半是实际花在这个程序上的。

程序实际占用的CPU时间一般比Elapsed Time要少不少：

![程序实际占用的CPU时间一般比Elapsed Time要少不少](images/0b340db019d7e389a2bde4c237ee4700.jpg)

> 备注：最好在云平台上，找一台 1 CPU 的机器来跑这个命令，在多 CPU 的机器上，seq 和 wc 两个命令可能分配到不同的 CPU 上，我们拿到的 user time 和 sys time 是两个 CPU 上花费的时间之和，可能会导致 real time 可能会小于 user time+sys time。



其次，即使我们已经拿到了 CPU 时间，我们也不一定可以直接“比较”出两个程序的性能差异。即使在同一台计算机上，CPU可能满载运行也可能**降频**运行，降频运行的时候自然花的时间会多一些。

除了 CPU 之外，时间这个性能指标还会受到主板、内存这些其他相关硬件的影响。所以，我们需要对“时间”这个我们可以感知的指标进行拆解，把程序的 CPU 执行时间变成 ==CPU时钟周期数（CPU Cycles）==和 ==时钟周期时间（Clock Cycle）==的乘积。

```
程序的CPU执行时间 = CPU时钟周期数 x 时钟周期时间
```

🔖



CPU时钟周期数 可以分解 “指令数×每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）“。



```
程序的CPU执行时间 = 指令数 × CPI × Clock Cycle Time
```

想要解决性能问题，其实就是要优化这三者:

1. 时钟周期时间，就是计算机主频。
2. 每条指令的平均时钟周期数 CPI，就是一条指令到底需要多少 CPU Cycle。
3. 指令数，代表执行我们的程序到底需要多少条指令、用哪些指令。这个很多时候就把挑战交给了编译器。同样的代码，编译成计算机指令时候，就有各种不同的表示方式。

> 我们可以把自己想象成一个 CPU，坐在那里写程序。计算机主频就好像是你的打字速度，打字越快，你自然可以多写一点程序。CPI 相当于你在写程序的时候，熟悉各种快捷键，越是打同样的内容，需要敲击键盘的次数就越少。指令数相当于你的程序设计得够合理，同样的程序要写的代码行数就少。如果三者皆能实现，你自然可以很快地写出一个优秀的程序，你的“性能”从外面来看就是好的。



一个程序对应多条语句，一条编程语句可能对应多条指令，一条CPU指令可能需要多个CPU周期才能完成。



## 4 穿越功耗墙，我们该从哪些方面提升“性能”？

如果要提升计算机的性能，我们可以从指令数、CPI以及CPU主频这三个地方入手。

指令数、CPI不怎么好弄，就针对CPU，在 CPU 上多放一点晶体管，不断提升 CPU的时钟频率，这样就能让CPU变得更快，程序的执行时间就会缩短。

### 功耗：CPU 的“人体极限”



相较于 1978 年到 2000 年，这 20 年里 300 倍的主频提升，从 2000 年到现在的这 19 年，CPU 的主频大概提高了 3 倍。

![CPU的主频变化，在奔腾4时代进入了瓶颈期](images/1826102a89e4cdd31f7573db53dd9280.png)



奔腾 4 的主频为什么没能超过 3.8GHz 的障碍呢？答案就是==功耗==问题。

> 例子：
>
> 一个 3.8GHz 的奔腾 4 处理器，满载功率是 130 瓦。这个 130 瓦是什么概念呢？机场允许带上飞机的充电宝的容量上限是 100 瓦时。如果我们把这个 CPU 安在手机里面，不考虑屏幕内存之类的耗电，这个 CPU 满载运行 45 分钟，充电宝里面就没电了。而 iPhone X 使用 ARM 架构的 CPU，功率则只有 4.5 瓦左右。

CPU一般都被叫作**超大规模集成电路（Very-Large-Scale Integration，VLSI）**。这些电路，实际上都是一个个晶体管组合而成的。CPU 在计算，其实就是让晶体管里面的“开关”不断地去“打开”和“关闭”，来组合完成各种运算和功能。

想要计算得快，一方面，我们要在 CPU 里，同样的面积里面，多放一些晶体管，也就是==增加密度==；另一方面，我们要让晶体管“打开”和“关闭”得更快一点，也就是==提升主频==。而这两者，都会增加功耗，带来耗电和散热的问题。

> 例子：
>
> 可以把一个计算机 CPU 想象成一个巨大的工厂，里面有很多工人，相当于 CPU 上面的晶体管，互相之间协同工作。
>
> 为了工作得快一点，我们要在工厂里多塞一点人。你可能会问，为什么不把工厂造得大一点呢？这是因为，人和人之间如果离得远了，互相之间走过去需要花的时间就会变长，这也会导致性能下降。这就好像如果 CPU 的面积大，晶体管之间的距离变大，电信号传输的时间就会变长，运算速度自然就慢了。
>
> 除了多塞一点人，我们还希望每个人的动作都快一点，这样同样的时间里就可以多干一点活儿了。这就相当于提升 CPU 主频，但是动作快，每个人就要出汗散热。要是太热了，对工厂里面的人来说会中暑生病，对CPU来说就会崩溃出错。

我们会在 CPU 上面抹硅脂、装风扇，乃至用上水冷或者其他更好的散热设备，就好像在工厂里面装风扇、空调，发冷饮一样。但是同样的空间下，装上风扇空调能够带来的散热效果也是有极限的。

因此，在 CPU 里面，能够放下的**晶体管数量和晶体管的“开关”频率也都是有限的**。一个 CPU 的功率可以用一个公式来表示：

```
功耗 ~= 1/2 × 负载电容 × 电压的平方 × 开关频率 × 晶体管数量
```

那么，为了要提升性能，我们需要不断地增加晶体管数量。同样的面积下，我们想要多放一点晶体管，就要把晶体管造得小一点。这个就是平时我们所说的提升“==制程==”。从 28nm 到 7nm，相当于晶体管本身变成了原来的 1/4 大小。这个就相当于我们在工厂里，同样的活儿，我们要找瘦小一点的工人，这样一个工厂里面就可以多一些人。我们还要提升主频，让开关的频率变快，也就是要找手脚更快的工人。

![](images/f59f2f33e308000cb5d2ad017f2ff8ed.jpeg)

但是，**功耗增加太多，就会导致 CPU 散热跟不上**，这时，我们就需要降低电压。这里有一点非常关键，在整个功耗的公式里面，功耗和电压的平方是成正比的。这意味着电压下降到原来的 1/5，整个的功耗会变成原来的 1/25。

事实上，从 5MHz 主频的 8086 到 5GHz 主频的 Intel i9，CPU 的电压已经从 5V 左右下降到了 1V 左右。这也是为什么我们 CPU 的主频提升了 1000 倍，但是功耗只增长了 40 倍。比如说，我写这篇文章用的是 Surface Go，在这样的轻薄笔记本上，微软就是选择了把电压下降到 0.25V 的低电压 CPU，使得笔记本能有更长的续航时间。

### 并行优化，理解阿姆达尔定律  🔖





# 原理篇：指令和运算

## 5 计算机指令：试试用纸带编程

“打孔卡（Punched Card）”



### 在软硬件接口中，CPU做了什么事？

CPU,Central Processing Unit，中央处理器。

从硬件的角度来看，CPU 就是一个超大规模集成电路，通过电路实现了加法、乘法乃至各种各样的处理逻辑。

从软件工程师的角度来讲，CPU 就是一个执行各种**计算机指令**（Instruction Code）的逻辑机器。这里的计算机指令，就好比一门 CPU 能够听得懂的语言，我们也可以把它叫作**机器语言**（Machine Language）。

不同的CPU有各自支持的“语言”，就是不同**==计算机指令集（Instruction Set）==**。

一个计算机程序，不可能只有一条指令，而是由成千上万条指令组成的。但是 CPU 里不能一直放着所有指令，所以计算机程序平时是存储在存储器中的。这种程序指令存储在存储器里面的计算机，就叫作==存储程序型计算机（Stored-program Computer）==。

> 非存储程序型计算机：早就发明了一种叫 Plugboard Computer 的计算设备。我把它直译成“插线板计算机”。在一个布满了各种插口和插座的板子上，工程师们用不同的电线来连接不同的插口和插座，从而来完成各种计算任务。
>
> ![](images/99eb1ab1cdbdfa2d35fce456940ca651.jpg)



### 从编译到汇编，代码怎么变成机器码？



```c
// test.c
int main()
{
  int a = 1; 
  int b = 2;
  a = a + b;
}
```

要让这段程序在一个Linux操作系统上跑起来，需要把整个程序翻译成一个==汇编语言（ASM，Assembly Language）==的程序，这个过程一般叫**编译（Compile）成汇编代码**。

可以再用==汇编器（Assembler）==翻译成==机器码（Machine Code）==。这些机器码由“0”和“1”组成的机器语言表示。这一条条机器码，就是一条条的计算机指令。这样一串串的 16 进制数字，就是CPU能够真正认识的计算机指令。

Linux中可以使用`gcc`和`objdump`把对应的汇编代码和机器码都打印出来：

```shell
$ gcc -g -c test.c
$ objdump -d -M intel -S test.o 

test.o：     文件格式 elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <main>:
// test.c
int main()
{
   0:   objdump: unrecognised disassembler option: intel
d10043ff        sub     sp, sp, #0x10
  int a = 1; 
   4:   52800020        mov     w0, #0x1                        // #1
   8:   b9000fe0        str     w0, [sp, #12]
  int b = 2;
   c:   52800040        mov     w0, #0x2                        // #2
  10:   b9000be0        str     w0, [sp, #8]
  a = a + b;
  14:   b9400fe1        ldr     w1, [sp, #12]
  18:   b9400be0        ldr     w0, [sp, #8]
  1c:   0b000020        add     w0, w1, w0
  20:   b9000fe0        str     w0, [sp, #12]
  24:   52800000        mov     w0, #0x0                        // #0
}
  28:   910043ff        add     sp, sp, #0x10
  2c:   d65f03c0        ret
```

左侧有一堆数字，这些就是一条条机器码；右边有一系列的 push、mov、add、pop 等，这些就是对应的汇编代码。一行 C 语言代码，有时候只对应一条机器码和汇编代码，有时候则是对应两条机器码和汇编代码。汇编代码和机器码之间是一一对应的。

> 可以直接把代码编译成机器码呀，为什么还需要汇编代码呢？
>
> 因为汇编代码其实就是“给程序员看的机器码”，也正因为这样，机器码和汇编代码是一一对应的。

![](images/67cf3c90ac9bde229352e1be0db24b5b.png)





### 解析指令和机器码

日常用的 Intel CPU，有 2000 条左右的 CPU 指令。

常见的指令可以分成五大类：

- 第一类是==算术类指令==。加减乘除，在CPU层面，都会变成一条条算术类指令。
- 第二类是==数据传输类指令==。给变量赋值、在内存里读写数据，用的都是数据传输类指令。
- 第三类是==逻辑类指令==。逻辑上的与或非，都是这一类指令。
- 第四类是==条件分支类指令==。日常写的“if/else”，其实都是条件分支类指令。
- 最后一类是==无条件跳转指令==。写一些大一点的程序，我们常常需要写一些函数或者方法。在调用函数的时候，其实就是发起了一个无条件跳转指令。

![](images/ebfd3bfe5dba764cdcf871e23b29f197.jpeg)

> 汇编器是怎么把对应的汇编代码，翻译成为机器码的？

不同的 CPU 有不同的指令集，也就对应着不同的汇编语言和不同的机器码。以最简单的MIPS指令集为例。

MIPS 是一组由 MIPS 技术公司在 80 年代中期设计出来的 CPU 指令集。就在最近，MIPS 公司把整个指令集和芯片架构都完全开源了。https://www.mips.com/mipsopen/

![](images/b1ade5f8de67b172bf7b4ec9f63589bf.jpeg)

MIPS 的指令是一个32位的整数，高6位叫==操作码（Opcode）==，也就是代表这条指令具体是一条什么样的指令，剩下的 26 位有三种格式，分别是 R、I 和 J。

- ==R指令==是一般用来做算术和逻辑操作，里面有读取和写入数据的寄存器的地址。如果是逻辑位移操作，后面还有位移操作的位移量，而最后的功能码，则是在前面的操作码不够的时候，扩展操作码表示对应的具体指令的。
- ==I指令==，则通常是用在数据传输、条件分支，以及在运算的时候使用的并非变量还是常数的时候。这个时候，没有了位移量和操作码，也没有了第三个寄存器，而是把这三部分直接合并成了一个地址值或者一个常数。
- ==J指令==就是一个跳转指令，高 6 位之外的 26 位都是一个跳转后的地址。



```
add $t0,$s2,$s1
```

以一个简单的加法算术指令为例：【下面都用十进制来表示对应的代码】

对应的 MIPS 指令里 opcode 是 0，rs 代表第一个寄存器 s1 的地址是 17，rt 代表第二个寄存器 s2 的地址是 18，rd 代表目标的临时寄存器 t0 的地址，是 8。因为不是位移操作，所以位移量是 0。把这些数字拼在一起，就变成了一个 MIPS 的加法指令。

![](images/8fced6ff11d3405cdf941f6742b5081d.jpeg)

回到打孔带。如果用打孔代表 1，没有打孔代表 0，用 4 行 8 列代表一条指令来打一个穿孔纸带，那么这条命令大概就长这样：

![](images/1e5ecb8c92b01defee1c2af8c864887c.png)



## 6 指令跳转：原来if...else就是goto

### CPU 是如何执行指令的？



![](images/cdba5c17a04f0dd5ef05b70368b9a96f.jpg)

一个 CPU 里面会有很多种不同功能的寄存器。三个比较特殊的：

- ==PC寄存器==（Program Counter Register），我们也叫指令地址寄存器（Instruction Address Register）。顾名思义，它就是用来存放下一条需要执行的计算机指令的内存地址。
- ==指令寄存器==（Instruction Register），用来存放当前正在执行的指令。
- ==条件码寄存器==（Status Register），用里面的一个一个标记位（Flag），存放 CPU 进行算术或者逻辑计算的结果。

有些寄存器既可以存放数据，又能存放地址，我们就叫它==通用寄存器==。



## 7 函数调用：为什么会发生stack overflow？

### 为什么需要程序栈？



### 如何构造一个 stack overflow？



### 如何利用函数内联进行性能优化？



叶子函数（或叶子过程）



## 8 ELF和静态链接：为什么程序无法同时在Linux和Windows下运行？

### 编译、链接和装载：拆解程序执行



![](images/997341ed0fa9018561c7120c19cfa2a7.jpg)

### ELF格式和链接：理解链接过程



![](images/276a740d0eabf5f4be905fe7326d9fb3.jpg)

ELF 文件格式把各种信息，分成一个一个的 Section 保存起来。ELF 有一个基本的文件头（File Header），用来表示这个文件的基本属性，比如是否是可执行文件，对应的 CPU、操作系统等等。除了这些基本属性之外，大部分程序还有这么一些 Section：

1. 首先是.text Section，也叫作**代码段**或者指令段（Code Section），用来保存程序的代码和指令；
2. 接着是.data Section，也叫作**数据段**（Data Section），用来保存程序里面设置好的初始化数据信息；
3. 然后就是.rel.text Secion，叫作**重定位表**（Relocation Table）。重定位表里，保留的是当前的文件里面，哪些跳转地址其实是我们不知道的。比如上面的 link_example.o 里面，我们在 main 函数里面调用了 add 和 printf 这两个函数，但是在链接发生之前，我们并不知道该跳转到哪里，这些信息就会存储在重定位表里；
4. 最后是.symtab Section，叫作**符号表**（Symbol Table）。符号表保留了我们所说的当前文件里面定义的函数名称和对应地址的地址簿。



![](images/f62da9b29aa53218f8907851df27f912.jpeg)

## 9 程序装载：“640K内存”真的不够用么？

### 程序装载面临的挑战

第一，可执行程序加载后占用的内存空间应该是连续的。

第二，我们需要同时加载很多个程序，并且不能让程序自己规定在内存中加载的位置。



虚拟内存地址（Virtual Memory Address）

物理内存地址（Physical Memory Address）



### 内存分段



### 内存分页



## 10 动态链接：程序内部的“共享单车”

“链接”其实有点儿像我们日常生活中的**标准化**、**模块化**生产。我们有一个可以生产标准螺帽的生产线，就可以生产很多个不同的螺帽。只要需要螺帽，我们都可以通过**链接**的方式，去**复制**一个出来，放到需要的地方去，大到汽车，小到信箱。

![](images/092dfd81e3cc45ea237bb85557bbfa51.jpg)

### 链接可以分动、静，共享运行省内存





### 地址无关很重要，相对地址解烦恼



### PLT 和 GOT，动态链接的解决方案



## 11 二进制编码：“手持两把锟斤拷，口中疾呼烫烫烫”？

### 理解二进制的“逢二进一”



### 字符串的表示，从编码到数字



## 12 理解电路：从电报机到门电路，我们如何做到“千里传信”？

### 从信使到电报，我们怎么做到“千里传书”？



### 理解继电器，给跑不动的信号续一秒



## 13 加法器：如何像搭乐高一样搭电路（上）？

### 异或门和半加器



### 全加器



## 14 乘法器：如何像搭乐高一样搭电路（下）？

### 顺序乘法的实现过程



### 并行加速方法



### 电路并行



## 15 浮点数和定点数（上）：怎么用有限的Bit表示尽可能多的信息？

### 浮点数的不精确性



### 定点数的表示



## 16 浮点数和定点数（下）：深入理解浮点数到底有什么用？

### 浮点数的二进制转化





### 浮点数的加法和精度损失





### Kahan Summation 算法











# 原理篇：处理器



## 17 建立数据通路（上）：指令+运算=CPU

### 指令周期（Instruction Cycle）



### 建立数据通路



### CPU 所需要的硬件电路



## 18 建立数据通路（中）：指令+运算=CPU

组合逻辑电路（Combinational Logic Circuit）

时序逻辑电路（Sequential Logic Circuit）



### 时钟信号的硬件实现



### 通过 D 触发器实现存储功能





## 19 建立数据通路（下）：指令+运算=CPU



### PC 寄存器所需要的计数器



### 读写数据所需要的译码器



### 建立数据通路，构造一个最简单的 CPU



## 20 面向流水线的指令设计（上）：一心多用的现代CPU



### 单指令周期处理器



### 现代处理器的流水线设计



### 超长流水线的性能瓶颈





## 21 面向流水线的指令设计（下）：奔腾4是怎么失败的？



### “主频战争”带来的超长流水线



### 新的挑战：冒险和分支预测





## 22 冒险和预测（一）：hazard是“危”也是“机”



### 结构冒险：为什么工程师都喜欢用机械键盘？





### 数据冒险：三种不同的依赖关系



#### 先写后读（Read After Write，RAW）



#### 先读后写（Write After Read，WAR）



#### 写后再写（Write After Write，WAW）





### 再等等：通过流水线停顿解决数据冒险



## 23 冒险和预测（二）：流水线里的接力赛

### NOP 操作和指令对齐



### 流水线里的接力赛：操作数前推





## 24 冒险和预测（三）：CPU里的“线程池”

### 填上空闲的 NOP：上菜的顺序不必是点菜的顺序





### CPU 里的“线程池”：理解乱序执行



## 25 冒险和预测（四）：今天下雨了，明天还会下雨么？

### 分支预测：今天下雨了，明天还会继续下雨么？





### 为什么循环嵌套的改变会影响性能？



## 26 Superscalar和VLIW：如何让CPU的吞吐率超过1？

### 多发射与超标量：同一时间执行的两条指令



### Intel 的失败之作：安腾的超长指令字设计





## 27 SIMD：如何加速矩阵乘法？

单指令多数据流（SIMD）技术

### 超线程：Intel 多卖给你的那一倍 CPU



### SIMD：如何加速矩阵乘法？



## 28 异常和中断：程序出错了怎么办？

### 异常：硬件、系统和应用的组合拳



### 异常的分类：中断、陷阱、故障和中止



### 异常的处理：上下文切换



## 29 CISC和RISC：为什么手机芯片都是ARM？

复杂指令集（Complex Instruction Set Computing，简称 CISC）

精简指令集（Reduced Instruction Set Computing，简称 RISC）



### Intel 的进化：微指令架构的出现



### ARM 和 RISC-V：CPU 的现在与未来



## 30 GPU（上）：为什么玩游戏需要使用GPU？

### GPU 的历史进程



### 图形渲染的流程



对于图像进行实时渲染的过程，可以被分解成下面这样 5 个步骤：

#### 1 顶点处理（Vertex Processing）



#### 2 图元处理（Primitive Processing）



#### 3 栅格化（Rasterization）



#### 4 片段处理（Fragment Processing）



#### 5 像素操作（Pixel Operations）



### 解放图形渲染的 GPU



## 31 GPU（下）：为什么深度学习需要使用GPU？



### Shader 的诞生和可编程图形处理器



### 现代 GPU 的三个核心创意



#### 芯片瘦身



#### 多核并行和 SIMT



#### GPU 里的“超线程”





### GPU 在深度学习上的性能差异



## 32 FPGA和ASIC：计算机体系结构的黄金时代

### FPGA

FPGA，也就是现场可编程门阵列（Field-Programmable Gate Array）



### ASIC

ASIC（Application-Specific Integrated Circuit），也就是专用集成电路



## 33 解读TPU：设计和拆解一块ASIC芯片

### TPU V1 想要解决什么问题？



### 深入理解 TPU V1

#### 快速上线和向前兼容，一个 FPU 的设计



#### 专用电路和大量缓存，适应推断的工作流程

![](images/6a14254b2bda4dd42adac6a2129e8bae.jpeg)

#### 细节优化，使用 8 Bits 数据







### 用数字说话，TPU 的应用效果





## 34 理解虚拟机：你在云上拿到的计算机是什么样的？

### 缘起分时系统



### 从“黑色星期五”到公有云



### 虚拟机的技术变迁















# 原理篇：存储和I/O系统

## 35 存储器层次结构全景：数据存储的大金字塔长什么样？

### 理解存储器的层次结构



SRAM

DRAM

存储器的层级结构

使用存储器的时候，该如何权衡价格和性能？



## 36 局部性原理：数据库性能跟不上，加个缓存就好了？

### 理解局部性原理



### 如何花最少的钱，装下亚马逊的所有商品？



## 37 高速缓存（上）：“4毫秒”究竟值多少钱？



## 38 高速缓存（下）：你确定你的数据更新了么？

### “隐身”的变量



### CPU 高速缓存的写入

写直达（Write-Through）



写回（Write-Back）



## 39 MESI协议：如何让多核CPU的高速缓存保持一致？

### 缓存一致性问题



### 总线嗅探机制和 MESI 协议



## 40 理解内存（上）：虚拟内存和内存保护是什么？

### 简单页表



### 多级页表



## 41 理解内存（下）：解析TLB和内存保护

### 加速地址转换：TLB



### 安全性与内存保护

#### 可执行空间保护



#### 地址空间布局随机化



## 42 总线：计算机内部的高速公路

### 降低复杂性：总线的设计思路来源



### 理解总线：三种线路和多总线架构



## 43 输入输出设备：我们并不是只能用灯泡显示“0”和“1”

### 接口和设备：经典的适配器模式



### CPU 是如何控制 I/O 设备的？



### 信号和地址：发挥总线的价值



## 44 理解IO_WAIT：I/O性能到底是怎么回事儿？

### IO 性能、顺序访问和随机访问



如何定位 IO_WAIT？



## 45 机械硬盘：Google早期用过的“黑科技”

### 拆解机械硬盘



### Partial Stroking：根据场景提升性能



## 46 SSD硬盘（上）：如何完成性能优化的KPI？

### SSD 的读写原理



### SLC、MLC、TLC 和 QLC



### P/E 擦写问题



### SSD 读写的生命周期



## 47 SSD硬盘（下）：如何完成性能优化的KPI？

磨损均衡、TRIM 和写入放大效应



FTL 和磨损均衡



TRIM 指令的支持



写入放大



AeroSpike：如何最大化 SSD 的使用效率？



## 48 DMA：为什么Kafka这么快？

直接内存访问（Direct Memory Access）技术



### Kafka 的实现原理





## 49 数据完整性（上）：硬件坏了怎么办？



### 单比特翻转：软件解决不了的硬件错误



### 奇偶校验和校验位：捕捉错误的好办法





## 50 数据完整性（下）：如何还原犯罪现场？

### 海明码：我们需要多少信息冗余？



### 海明码的纠错原理



### 海明距离：形象理解海明码的作用



## 51 分布式计算：如果所有人的大脑都联网会怎样？

### 从硬件升级到水平扩展



### 理解高可用性和单点故障













# 应用篇

理解了计算机各个组件的运作之后，最后一个模块将手把手带你实操。利用存储器层次结构设计大型 DMP 系统，并通过 Disruptor，跟你一起感受 CPU 的风驰电掣，让你真正学有所用。

## 52 设计大型DMP系统（上）：MongoDB并不是什么灵丹妙药



DMP：数据管理平台



## 53 设计大型DMP系统（下）：SSD拯救了所有的DBA

### 关系型数据库：不得不做的随机读写



### Cassandra：顺序写和随机读

Cassandra 的数据模型



Cassandra 的读操作



### SSD：DBA 们的大救星



## 54 理解Disruptor（上）：带你体会CPU高速缓存的风驰电掣

### Padding Cache Line，体验高速缓存的威力



### 使用 RingBuffer，利用缓存和分支预测





## 55 理解Disruptor（下）：不需要换挡和踩刹车的CPU，有多快？

### 缓慢的锁



### 无锁的 RingBuffer





